model_name_or_path: root/autodl-tmp/LLaMA3.1-70B-Chat
template: llama3
infer_backend: vllm
vllm_enforce_eager: trues
vllm_maxlen: 32768
