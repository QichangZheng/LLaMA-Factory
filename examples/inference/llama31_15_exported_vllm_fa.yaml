model_name_or_path: /root/autodl-tmp/llama31_15
template: llama3
infer_backend: vllm
vllm_enforce_eager: true
vllm_maxlen: 2048
flash_attn: fa2
